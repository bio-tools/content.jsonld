{
  "@context": {
    "bsc": "http://bioschemas.org/",
    "edam": "http://edamontology.org/",
    "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
    "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
    "sc": "http://schema.org/",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@graph": [
    {
      "@id": "https://bio.tools/FaceSync",
      "@type": "sc:SoftwareApplication",
      "sc:additionalType": "Library",
      "sc:applicationSubCategory": [
        {
          "@id": "edam:topic_3474"
        },
        {
          "@id": "edam:topic_3794"
        }
      ],
      "sc:citation": {
        "@id": "https://doi.org/10.12688/F1000RESEARCH.18187.1"
      },
      "sc:description": "Open source framework for recording facial expressions with head-mounted cameras | The FaceSync toolbox provides 3D blueprints for building the head-mounted camera setup described in our paper. The toolbox also provides functions to automatically synchronize videos based on audio, manually align audio, plot facial landmark movements, and inspect synchronized videos to graph data",
      "sc:featureList": {
        "@id": "edam:operation_3192"
      },
      "sc:license": "MIT",
      "sc:name": "FaceSync",
      "sc:url": "https://github.com/cosanlab/facesync"
    },
    {
      "@id": "https://doi.org/10.12688/F1000RESEARCH.18187.1",
      "@type": "sc:CreativeWork"
    }
  ]
}